---
layout: jupyter
title: 자연어 처리 - 웹 스크래핑(Selenium)
published: true
date: 2023-01-11
description: 웹 스크래핑(Selenium)
comments: true
categories:
 - NLP
tags:
 - python
 - NLP
toc: true
toc_sticky: true
toc_label: 웹 스크래핑(Selenium)
use_math: true
---
---
# Selenium

* 동적 웹 스크래핑  
BeautifulSoup만으로는 직접적인 주소가 노출되지 않은 자바스크립트로 이뤄진 페이지의 트래킹이 불가능하다.  
Selenium는 자바스크립트를 실행할 수 있다.

[Selenium Web Driver for chrome](https://chromedriver.chromium.org/downloads)

## 커피빈 매장 찾기 페이지 분석

<div class="in_prompt">
In&nbsp;[1]:
</div>

<div class="input_area" markdown="1">

```python
# !pip install selenium
```

</div>

<div class="in_prompt">
In&nbsp;[2]:
</div>

<div class="input_area" markdown="1">

```python
from selenium import webdriver
from bs4 import BeautifulSoup
import time
```

</div>

<div class="in_prompt">
In&nbsp;[3]:
</div>

<div class="input_area" markdown="1">

```python
# !pip install webdriver_manager
```

</div>

<div class="in_prompt">
In&nbsp;[4]:
</div>

<div class="input_area" markdown="1">

```python
# from webdriver_manager.chrome import ChromeDriverManager
# from selenium.webdriver.chrome.service import Service

# wd = webdriver.Chrome(service=Service(ChromeDriverManager().install())) # chrome버전에 맞게 알아서 chromedriver를 실행
    
# wd.get('https://www.coffeebeankorea.com/store/store.asp')
# time.sleep(1)
# wd.execute_script("storePop2('1')")
# time.sleep(1)
# html = wd.page_source

# soupCB = BeautifulSoup(html, 'html.parser')
# store_name = soupCB.select('div.store_txt>h2')[0].text
# store_name

# wd.quit()
```

</div>

<div class="in_prompt">
In&nbsp;[5]:
</div>

<div class="input_area" markdown="1">

```python
wd = webdriver.Chrome('chromedriver109.exe')

for store_num in range(50):
    try:
        wd.get('https://www.coffeebeankorea.com/store/store.asp')
        time.sleep(1)
        wd.execute_script(f"storePop2('{store_num}')")
        time.sleep(1)
        html = wd.page_source

        soupCB = BeautifulSoup(html, 'html.parser')
        store_name = soupCB.select('div.store_txt>h2')[0].text
        store_info = soupCB.select("tbody>tr>td")
        store_address = store_info[2].text
        store_tel = store_info[3].text

        print(store_num, store_name, store_address, store_tel, sep='/')
    except IndexError:
        continue
        
wd.quit()
```

</div>

<div class="output_prompt">
Out&nbsp;[5]:
</div>

{:.output_stream}

```
C:\Users\user\AppData\Local\Temp\ipykernel_13960\712883531.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object
  wd = webdriver.Chrome('chromedriver109.exe')

```

{:.output_stream}

```
1/학동역 DT점/서울시 강남구 학동로 211 1층  /02-3444-9973
3/차병원점/서울시 강남구 논현로 566 강남차병원1층  /02-538-7615
6/강남대로점/서울시 서초구 강남대로 369 1층  /02-588-5778
11/강남에스점/서울시 서초구 서초 1306-3호  /02-593-5095
12/청담에스점/서울시 강남구 압구정로 461 네이처포엠빌딩B108,109호  /02-548-6052
13/신사점/서울시 강남구 도산대로 126  /02-548-2741
14/압구정역점/서울시 강남구 논현로 842 압구정빌딩1층  /02-544-6823
15/역삼점/서울시 강남구 논현로 512  지상1,2층  /02-569-8051
16/양재스포타임점/서울시 서초구 강남대로 213 24호 지하1층  /02-578-6833
17/청담성당점/서울시 강남구 삼성로 716 LEE76빌딩2층  /02-542-2053
18/영동점/서울 서초구 반포동 736-17 P빌딩 2층  /02-3443-2096
19/도곡점/서울시 강남구 언주로 30길 10,112 현대비젼21 112호  /02-572-2781
20/영동고앞점/서울시 강남구 선릉로 749 1,2층  /02-544-3794
25/압구정시티점/서울시 강남구 도산대로49길 13 1층 17,18호  /02-543-5922
26/압구정로데오점/서울시 강남구 선릉로 157길 12 석전빌딩 1~4층  /02-3445-5093
27/서초우성점/서울시 서초구 강남대로 51길 1 511 TOWER  1층  /02-582-0158
28/논현팍스타워점/서울시 강남구 논현 231-13호 팍스타워지하1층  /02-513-3870
29/삼성오크우드점/서울 강남구 영동대로 513 컨벤션별관A동 지하 2층  /02-3466-8507
30/트레이드타워점/서울시 강남구 영동대로 511 트레이드타워 지하1층  /02-6002-6470
31/삼성봉은사거리점/서울시 강남구 영동대로 607 1,2층  /02-3443-5618
34/반포엘루체점/서울시 서초구 신반포로 23 1141호 엘루체백화점내1층1013~1015호  /02-3477-5571
35/잠실신천점/서울시 송파구 석촌호수로 118 1층  /02-416-9520
36/서초지파이브점/서울시 서초구 서초동 1685-8호 101~2호,113~4호,121호  /02-3477-5580
38/논현동수면센터점/서울시 강남구 논현로 717 1층  /02-3443-5575
41/삼성전자강남사옥점/서울시 서초구 서초대로74길 11 지하2층  /02-2055-1142
44/삼성생명강남사옥점/서울시 서초구 서초대로74길 4 삼성생명보험서초타워내지하1층  /02-581-5562
45/방배카페골목점/서울특별시 서초구 방배중앙로 187  /02-592-7794
46/역삼포스틸타워뒷점/서울시 강남구 테헤란로 20길 10 쓰리엠타워1층  /02-554-9962
47/테헤란로하이닉스뒷점/서울시 강남구 테헤란로 70길 12 1층  /02-538-9927
49/삼성봉은사로점/서울시 강남구 봉은사로 628 엘슨빌딩1층  /02-538-4523

```

## 네이버 뉴스 스크래핑

<div class="in_prompt">
In&nbsp;[6]:
</div>

<div class="input_area" markdown="1">

```python
import requests
from bs4 import BeautifulSoup

url = 'https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&sid1=001&sid2=140&oid=001&isYeonhapFlash=Y'
headers = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36"}
# https://www.whatsmyua.info/ 에서 확인 가능
# Chrome: F12 -> Console> navigator.userAgent 에서 확인 가능

res = requests.get(url, headers=headers)
soup = BeautifulSoup(res.content, 'html.parser')
```

</div>

# 추가예정
